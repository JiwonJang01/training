{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebfdb7ec-09b4-4992-95e4-de1e4634677f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder,StringIndexer,VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import col, stddev_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edeee723-619c-497e-8e54-6c84d18c5aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data - 수집\n",
    "# data processing - EDA\n",
    "# model create or choice\n",
    "# training\n",
    "# predict(classification / regression)\n",
    "# score\n",
    "# 배포 - 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5742256-8d1c-4790-9dfb-25f213dd24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'titanic/train.csv'\n",
    "test_path = 'titanic/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74688f8-38ca-4af1-89b6-c6a028a22b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('csv')\\\n",
    "    .options(header='true', inferSchema='true')\\\n",
    "    .load(train_path).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8f4e00-5046-4474-86fb-dd950a601ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e77dba-1133-48c2-a4b0-e96e55e1a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|Survived|\n",
      "+--------+\n",
      "|       1|\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\"Survived\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4c08c6-4c3c-421b-96e9-2ba38619b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF재구성\n",
    "train_df = df.select('Survived', 'Sex', 'Pclass', 'Age','Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356918c8-cb3b-4a58-88ae-837bc504e6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+\n",
      "|Survived|   Sex|Pclass| Age|   Fare|\n",
      "+--------+------+------+----+-------+\n",
      "|       0|  male|     3|22.0|   7.25|\n",
      "|       1|female|     1|38.0|71.2833|\n",
      "|       1|female|     3|26.0|  7.925|\n",
      "|       1|female|     1|35.0|   53.1|\n",
      "|       0|  male|     3|35.0|   8.05|\n",
      "|       0|  male|     3|NULL| 8.4583|\n",
      "|       0|  male|     1|54.0|51.8625|\n",
      "|       0|  male|     3| 2.0| 21.075|\n",
      "|       1|female|     3|27.0|11.1333|\n",
      "|       1|female|     2|14.0|30.0708|\n",
      "|       1|female|     3| 4.0|   16.7|\n",
      "|       1|female|     1|58.0|  26.55|\n",
      "|       0|  male|     3|20.0|   8.05|\n",
      "|       0|  male|     3|39.0| 31.275|\n",
      "|       0|female|     3|14.0| 7.8542|\n",
      "|       1|female|     2|55.0|   16.0|\n",
      "|       0|  male|     3| 2.0| 29.125|\n",
      "|       1|  male|     2|NULL|   13.0|\n",
      "|       0|female|     3|31.0|   18.0|\n",
      "|       1|female|     3|NULL|  7.225|\n",
      "+--------+------+------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eaff26b-7d58-47a3-81e1-0247610254e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+------+---+----+\n",
      "|Survived|Sex|Pclass|Age|Fare|\n",
      "+--------+---+------+---+----+\n",
      "|       0|  0|     0|177|   0|\n",
      "+--------+---+------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인하기\n",
    "from pyspark.sql.functions import *\n",
    "train_df.select([count(when(isnull(c),c)).alias(c) for c in train_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6bd9a9-8d39-4014-bb75-d708f4f6a514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------+\n",
      "|   Sex|Pclass|          avg(Age)|\n",
      "+------+------+------------------+\n",
      "|  male|     3|26.507588932806325|\n",
      "|female|     3|             21.75|\n",
      "|female|     1| 34.61176470588235|\n",
      "|female|     2|28.722972972972972|\n",
      "|  male|     2| 30.74070707070707|\n",
      "|  male|     1| 41.28138613861386|\n",
      "+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측치 채우기 성별에 따른 객실 등에 대한 Age들의 평균값으로 채운다.\n",
    "avg_mean = train_df.groupBy('Sex','Pclass').agg(avg('Age')).alias('avg_mean')\n",
    "avg_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b68bd9d2-3d4d-450f-949a-00e0d83f07cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+----+-------+------------------+\n",
      "|   Sex|Pclass|Survived| Age|   Fare|         AgeFilled|\n",
      "+------+------+--------+----+-------+------------------+\n",
      "|  male|     3|       0|22.0|   7.25|              22.0|\n",
      "|female|     1|       1|38.0|71.2833|              38.0|\n",
      "|female|     3|       1|26.0|  7.925|              26.0|\n",
      "|female|     1|       1|35.0|   53.1|              35.0|\n",
      "|  male|     3|       0|35.0|   8.05|              35.0|\n",
      "|  male|     3|       0|NULL| 8.4583|26.507588932806325|\n",
      "|  male|     1|       0|54.0|51.8625|              54.0|\n",
      "|  male|     3|       0| 2.0| 21.075|               2.0|\n",
      "|female|     3|       1|27.0|11.1333|              27.0|\n",
      "|female|     2|       1|14.0|30.0708|              14.0|\n",
      "|female|     3|       1| 4.0|   16.7|               4.0|\n",
      "|female|     1|       1|58.0|  26.55|              58.0|\n",
      "|  male|     3|       0|20.0|   8.05|              20.0|\n",
      "|  male|     3|       0|39.0| 31.275|              39.0|\n",
      "|female|     3|       0|14.0| 7.8542|              14.0|\n",
      "|female|     2|       1|55.0|   16.0|              55.0|\n",
      "|  male|     3|       0| 2.0| 29.125|               2.0|\n",
      "|  male|     2|       1|NULL|   13.0| 30.74070707070707|\n",
      "|female|     3|       0|31.0|   18.0|              31.0|\n",
      "|female|     3|       1|NULL|  7.225|             21.75|\n",
      "+------+------+--------+----+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 성별 및 객실별로 그룹화하여 평균 나이 계산\n",
    "mean_age_by_sex_pclass = df.groupBy(\"Sex\", \"Pclass\").agg(avg(\"Age\").alias(\"MeanAge\"))\n",
    "# 결측치를 해당 그룹의 평균 나이로 채우기\n",
    "filled_df = train_df.join(mean_age_by_sex_pclass, [\"Sex\", \"Pclass\"], \"left\") \\\n",
    "              .withColumn(\"AgeFilled\", when(col(\"Age\").isNull(), col(\"MeanAge\")).otherwise(col(\"Age\"))) \\\n",
    "              .drop(\"MeanAge\")\n",
    "# 결과 확인\n",
    "filled_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e335c8cd-9707-406e-aa1a-eed547b01d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 891)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_df.count(),df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f85795fb-755c-4dfa-96a5-ae66f9dd13be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex #범주형 StringIndex\n",
    "# Age #연속형 scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd0fb99a-4904-434d-9a0a-e06ece916677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **params # unpacking\n",
    "# StringIndexer(outputCol=\n",
    "\n",
    "params = {\n",
    "    'inputCol':'Sex',\n",
    "    'outputCol':'SexIdx'\n",
    "}\n",
    "strIdx = StringIndexer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03050f3d-763e-480b-99a6-48ebe4040b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치ㅇ 데이터에 대해서\n",
    "# 의류사이즈 2XL XL L M S --> labeling(4,3,2,1,0) -> onehot(10000, 01000, 00100, 00001) : 이 경우 onehot으로 하ㄴ 안됨\n",
    "params = {\n",
    "    'inputCol':'SexIdx',\n",
    "    'outputCol':'SexClassVec'\n",
    "}\n",
    "encode = OneHotEncoder(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c80a459-8a15-4448-8446-062fc133a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정답\n",
    "params = {\n",
    "    'inputCol':'Survived',\n",
    "    'outputCol':'label'\n",
    "}\n",
    "label_strIdx = StringIndexer(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35e08715-fd3f-456c-b6e2-9b3cade90977",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = [strIdx, encode, label_strIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6f375fe-a016-4bb9-99ee-6509fabed65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 범주형 데이터에 대한 전처리 준비 끝.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "633f1d11-265a-4ec8-bf92-dd1fda3951a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 연속형 데이터 / 수치형 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "037289d5-9a5b-42de-985d-e55d69678558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+--------+----+----+---------+\n",
      "| Sex|Pclass|Survived| Age|Fare|AgeFilled|\n",
      "+----+------+--------+----+----+---------+\n",
      "|male|     3|       0|22.0|7.25|     22.0|\n",
      "+----+------+--------+----+----+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filled_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48a9f919-eb7d-4425-b60b-cfd1666bf765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+--------+----+----+\n",
      "| Sex|Pclass|Survived| Age|Fare|\n",
      "+----+------+--------+----+----+\n",
      "|male|     3|       0|22.0|7.25|\n",
      "+----+------+--------+----+----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filled_df = filled_df.drop('AgeFilled')\n",
    "filled_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3533e360-6a8b-47d3-afc4-1d4b305c688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e4cf329-7dc9-468b-a3cf-eba29011bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCols = ['Age','Fare']\n",
    "# scaling\n",
    "for c in numCols:\n",
    "    filled_df = filled_df.withColumn(c+'Scaled', col(c) / df.agg(stddev_samp(c)).first()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc953424-9c56-420d-9572-a91eb2d2b45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+\n",
      "|         AgeScaled|         FareScaled|\n",
      "+------------------+-------------------+\n",
      "|1.5144738264626911|0.14589454188740145|\n",
      "|2.6159093366173756| 1.4344612962375451|\n",
      "+------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filled_df.select('AgeScaled','FareScaled').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f5fa2e6-5b92-4e53-a790-cbfb955fb428",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = ['SexClassVec', 'AgeScaled','FareScaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0af96404-e0f9-46c8-b41a-1e6d9fb9a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=inputs,outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7058cf9b-71d7-4d44-8c9d-436ac0d0d0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_73c1f305fc07,\n",
       " OneHotEncoder_4db7b4f51bc9,\n",
       " StringIndexer_81be67311d07,\n",
       " VectorAssembler_0868b43d575a]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage +=[assembler]\n",
    "stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49357a5b-c51d-463c-8a0d-e9eaeadbbfa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# pipe line \n",
    "pipeline = Pipeline(stages=stage)\n",
    "pipelineModel =  pipeline.fit(df)\n",
    "dataset =  pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20a42ba2-3715-46d9-ba90-5fca8c0d45f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+----+-------+-------------------+-------------------+\n",
      "|   Sex|Pclass|Survived| Age|   Fare|          AgeScaled|         FareScaled|\n",
      "+------+------+--------+----+-------+-------------------+-------------------+\n",
      "|  male|     3|       0|22.0|   7.25| 1.5144738264626911|0.14589454188740145|\n",
      "|female|     1|       1|38.0|71.2833| 2.6159093366173756| 1.4344612962375451|\n",
      "|female|     3|       1|26.0|  7.925| 1.7898327040013622|0.15947782682174572|\n",
      "|female|     1|       1|35.0|   53.1| 2.4093901784633722| 1.0685517481684161|\n",
      "|  male|     3|       0|35.0|   8.05| 2.4093901784633722| 0.1619932499577354|\n",
      "|  male|     3|       0|NULL| 8.4583|               NULL|0.17020962808913206|\n",
      "|  male|     1|       0|54.0|51.8625|   3.71734484677206| 1.0436490591221181|\n",
      "|  male|     3|       0| 2.0| 21.075|0.13767943876933555|   0.42410034072786|\n",
      "|female|     3|       1|27.0|11.1333|   1.85867242338603|0.22403968319931125|\n",
      "|female|     2|       1|14.0|30.0708| 0.9637560713853489| 0.6051262883017478|\n",
      "+------+------+--------+----+-------+-------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filled_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcc1c522-c03d-441f-ae87-f5131f776957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, split -- why?\n",
    "# 7 : 3\n",
    "# 7.5 : 2.5\n",
    "(train,test) = filled_df.randomSplit([0.7,0.3],seed=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "288203a1-969b-43b9-89aa-e69ea90306ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(593, 298, 891)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count(), test.count(), dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c93cc4d-c37c-4cc6-9ffd-7466dccacc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용과 평가용 데이터 준비 끝~~ 결측치와 이상치, 그리고 피처엔지니어링과 같은 고급 기법은 적용안함)\n",
    "# 단지 스케일만 맞줘줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "086db542-842b-4b2e-b89b-9328dd6800ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적절한 모델 준비\n",
    "lr = LogisticRegression(labelCol='label',featuresCol=\"features\", maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "739c99ef-4fb6-492f-b3a2-06e3d8aecf7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "features does not exist. Available: Sex, Pclass, Survived, Age, Fare, AgeScaled, FareScaled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lrModel \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#훈련\u001b[39;00m\n\u001b[1;32m      2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m lrModel\u001b[38;5;241m.\u001b[39mtransform(test) \u001b[38;5;66;03m# 예측\u001b[39;00m\n\u001b[1;32m      3\u001b[0m predictions\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[0;32m~/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m~/spark/python/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m~/spark/python/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/spark/python/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: features does not exist. Available: Sex, Pclass, Survived, Age, Fare, AgeScaled, FareScaled"
     ]
    }
   ],
   "source": [
    "lrModel = lr.fit(train) #훈련\n",
    "predictions = lrModel.transform(test) # 예측\n",
    "predictions.select('default','prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f016f08-3a44-4d34-83ee-1e400e08df16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0cd81-4a4d-4986-ac25-bd3b5f117be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822326dd-bf08-4507-ab26-510d414fdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator =  BinaryClassificationEvaluator(rawPredictionCol='rawPrediction')\n",
    "evaluator.evaluate(predictions)  # AUC (Binary Classification Evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56d28ecf-eece-4067-8def-b4efb3611e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 같은 방식의 평가는 일반화 시킬 수 있을까\n",
    "# 교차 검증을 통해 신뢰성 확보\n",
    "# 각종 파라메터의 값이 변경됨에 따라 모델의 성능이 달라진다\n",
    "# 하이퍼 파라미터 튜닝 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340f7c1-c946-4a08-840d-4c2f4667bf37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
