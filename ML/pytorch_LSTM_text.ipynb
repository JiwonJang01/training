{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "데이터 불러오기"
      ],
      "metadata": {
        "id": "OghUmRCIt1JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/new_york_times.zip' -d new_york_times"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjhTTZYdt1_Z",
        "outputId": "07e2dc01-4013-4cae-953f-b6270b1c7ad8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  inflating: new_york_times/CommentsApril2018.csv  \n",
            "  inflating: new_york_times/CommentsFeb2017.csv  \n",
            "  inflating: new_york_times/CommentsFeb2018.csv  \n",
            "  inflating: new_york_times/CommentsJan2017.csv  \n",
            "  inflating: new_york_times/CommentsJan2018.csv  \n",
            "  inflating: new_york_times/CommentsMarch2017.csv  \n",
            "  inflating: new_york_times/CommentsMarch2018.csv  \n",
            "  inflating: new_york_times/CommentsMay2017.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob"
      ],
      "metadata": {
        "id": "IGVAD-dUwrzI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = glob.glob('./new_york_times/*.csv')\n",
        "files[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dxnWwTQYwxzU",
        "outputId": "64a80155-44de-4004-b984-7c107a60c0e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./new_york_times/ArticlesFeb2017.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string"
      ],
      "metadata": {
        "id": "LQCRrLvVw3kU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xIbxwvu5xGef",
        "outputId": "7178ff99-af05-4d3b-e1b0-7c498a238fb2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(files[0])\n",
        "df.headline[:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-OwM6ExKfH",
        "outputId": "20ebc407-ac75-4815-9acf-0accdbaa8d0e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    N.F.L. vs. Politics Has Been Battle All Season...\n",
              "1                               Voice. Vice. Veracity.\n",
              "2                          A Stand-Up’s Downward Slide\n",
              "3              New York Today: A Groundhog Has Her Day\n",
              "4                 A Swimmer’s Communion With the Ocean\n",
              "5                                       Trail Activity\n",
              "Name: headline, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특수문자 제거(string.punctuation) -> 각 단어마다 고유수자를 numbering(dictionary)"
      ],
      "metadata": {
        "id": "bgnkl7T3xdNo"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.headline[11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Llc2jV-Px3uf",
        "outputId": "1b1cacb8-6d7e-45ce-cb3b-198459c4f30b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Questions for: ‘On Alaska’s Coldest Days, a Village Draws Close for Warmth’'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = \"\".join(chr for chr in df.headline[11] if chr not in string.punctuation  )"
      ],
      "metadata": {
        "id": "r3mGuoPYx6QW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dic = {}\n",
        "for v in temp.split():\n",
        "  if v not in temp_dic.keys():\n",
        "    temp_dic[v] = len(temp_dic.keys())"
      ],
      "metadata": {
        "id": "FgiflbL7yIdA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_dic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri5ZYMZCylFw",
        "outputId": "f7011aa2-a9c0-4f58-a045-2052d989ddee"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Questions': 0,\n",
              " 'for': 1,\n",
              " '‘On': 2,\n",
              " 'Alaska’s': 3,\n",
              " 'Coldest': 4,\n",
              " 'Days': 5,\n",
              " 'a': 6,\n",
              " 'Village': 7,\n",
              " 'Draws': 8,\n",
              " 'Close': 9,\n",
              " 'Warmth’': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습용 데이터셋"
      ],
      "metadata": {
        "id": "DIvX5Z74zOfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import glob\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "metadata": {
        "id": "yvSutY7TzEUB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class TextGeneration(Dataset):\n",
        "  def __init__(self):\n",
        "    # 모든 파일의 헤더라인의 텍스를 불러옴\n",
        "    all_headlines = []\n",
        "    for file in glob.glob('./new_york_times/*.csv'):\n",
        "      if 'Articles' in file:\n",
        "        df = pd.read_csv(file)\n",
        "        all_headlines.extend( list(df.headline.values) )\n",
        "        break\n",
        "    # 'Unknown' 제거\n",
        "    all_headlines = [h for h in all_headlines if h != 'Unknown']\n",
        "    self.corpus =  [self.clean_text(x) for x in all_headlines ]  # 말뭉치\n",
        "    self.BOW = {}\n",
        "\n",
        "    for line in self.corpus:\n",
        "      for word in line.split():\n",
        "        if word not in self.BOW.keys():\n",
        "          self.BOW[word] = len(self.BOW.keys())\n",
        "\n",
        "    # 모델의 입력으로 사용할 데이터\n",
        "    self.data = self.generate_sequence(self.corpus)\n",
        "\n",
        "  def clean_text(self, txt): # 특수문자 제거\n",
        "    txt = ''.join( v for v in txt if v not in string.punctuation).lower()\n",
        "    return txt\n",
        "\n",
        "  def generate_sequence(self, txt):\n",
        "    seq = []\n",
        "    for line in txt:\n",
        "      line = line.split()\n",
        "      line_bow = [self.BOW[word] for word in line]\n",
        "      # 단어2개를 입력으로, 그 다음 단어를 정답\n",
        "      data = [ ( [line_bow[i],line_bow[i+1] ] ,line_bow[i+2] )  for i in range(len(line_bow)-2)  ]\n",
        "      seq.extend(data)\n",
        "    return seq\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, index):\n",
        "    data = np.array(self.data[index][0])\n",
        "    label = np.array(self.data[index][1]).astype(np.float32)\n",
        "    return data, label"
      ],
      "metadata": {
        "id": "zbxwJlfNzYjG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "dataset = TextGeneration()\n",
        "loader = DataLoader(dataset, batch_size=64)\n",
        "data, label = next(iter(loader))\n",
        "data.shape, label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ukVlAIo7ukV",
        "outputId": "227c8d4d-8203-487c-b1be-022bcb1bb336"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 2]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self,num_embeddings):\n",
        "    super(LSTM, self).__init__()\n",
        "    # 희소벡터 - 밀집벡터 : 임베딩층\n",
        "    self.embed = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=16)\n",
        "    # LSTM층을 5개 쌓음\n",
        "    self.lstm = nn.LSTM(\n",
        "        input_size = 16, hidden_size = 64, num_layers=5,batch_first=True\n",
        "    )\n",
        "    # 분류 MLP  (2,64)\n",
        "    self.fc1 = nn.Linear(in_features=2*64, out_features=num_embeddings)\n",
        "    self.fc2 = nn.Linear(in_features=num_embeddings, out_features=num_embeddings)\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self, x):\n",
        "    x = self.embed(x)\n",
        "    x, _ = self.lstm(x)  # RNN처럼 전체출력,마지막 은닉층의 상태 반환 # 64, 2, 64\n",
        "    x = torch.reshape(x, (x.shape[0],-1))  # 64, 128\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "T96TUrud9DwA"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습루프"
      ],
      "metadata": {
        "id": "3kEM0ShEAoR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 데이터셋\n",
        "# 로더\n",
        "# 모델\n",
        "# 옵티마이져\n",
        "dataset = TextGeneration()\n",
        "loader = DataLoader(dataset,batch_size=64)\n",
        "model = LSTM(num_embeddings=len(dataset.BOW) ).to(device)\n",
        "optim = Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "A4iAZrtFAExx"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  iterator = tqdm.tqdm(loader)\n",
        "  for data, label in iterator:\n",
        "    # 기울기 초기화\n",
        "    optim.zero_grad()\n",
        "    # 모델의 예측값\n",
        "    pred = model(torch.tensor(data,dtype=torch.long).to(device) )\n",
        "    # 정답도 long tensor\n",
        "    loss = nn.CrossEntropyLoss()(pred, torch.tensor(label,dtype=torch.long).to(device) )\n",
        "    # 오차 역전파\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n",
        "    iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n",
        "# 모델저장\n",
        "torch.save(model.state_dict(),'lstm.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNBOCIxPKl-A",
        "outputId": "4da5b74d-65cb-415d-990a-fbdf02f132c9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/59 [00:00<?, ?it/s]<ipython-input-65-41d49411480e>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  pred = model(torch.tensor(data,dtype=torch.long).to(device) )\n",
            "<ipython-input-65-41d49411480e>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss = nn.CrossEntropyLoss()(pred, torch.tensor(label,dtype=torch.long).to(device) )\n",
            "epoch:1 loss:6.523890018463135: 100%|██████████| 59/59 [00:12<00:00,  4.88it/s]\n",
            "epoch:2 loss:6.4290313720703125: 100%|██████████| 59/59 [00:10<00:00,  5.51it/s]\n",
            "epoch:3 loss:6.367801189422607: 100%|██████████| 59/59 [00:13<00:00,  4.50it/s]\n",
            "epoch:4 loss:6.260339260101318: 100%|██████████| 59/59 [00:09<00:00,  6.45it/s]\n",
            "epoch:5 loss:6.176182746887207: 100%|██████████| 59/59 [00:10<00:00,  5.54it/s]\n",
            "epoch:6 loss:6.140148639678955: 100%|██████████| 59/59 [00:12<00:00,  4.90it/s]\n",
            "epoch:7 loss:6.076382160186768: 100%|██████████| 59/59 [00:08<00:00,  6.89it/s]\n",
            "epoch:8 loss:6.0234293937683105: 100%|██████████| 59/59 [00:10<00:00,  5.60it/s]\n",
            "epoch:9 loss:5.920074462890625: 100%|██████████| 59/59 [00:11<00:00,  5.02it/s]\n",
            "epoch:10 loss:5.629584789276123: 100%|██████████| 59/59 [00:08<00:00,  6.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델성능평가 : 문장생성"
      ],
      "metadata": {
        "id": "e0Au7I--N-tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(model, BOW, str_data = \"finding an \",strlen=10):\n",
        "  device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "  with torch.no_grad():\n",
        "    for p in range(strlen):\n",
        "      # 입력을 텐서로 변환\n",
        "\n",
        "      words = torch.tensor([  BOW[w] for w in str_data.split() ], dtype=torch.long).to(device)\n",
        "      # 입력으로 사용가능하게  배치차원 추가  문장의 마지막 두 단어를 선택\n",
        "      input_tensor = torch.unsqueeze(words[-2:],dim=0)\n",
        "      # (1, 2)\n",
        "      output = model(input_tensor)\n",
        "      output_word = (torch.argmax(output).cpu().numpy()) # 최대 값이 들어 있는 번호를 반환\n",
        "      str_data += list(BOW.keys())[output_word]\n",
        "      str_data += \" \"\n",
        "\n",
        "  print(f\"predict sentence : {str_data}\")"
      ],
      "metadata": {
        "id": "EiRPGPDsL53D"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('lstm.pth', map_location=device))\n",
        "pred = generator(model, dataset.BOW)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVtciDa0PUnB",
        "outputId": "01e7b6c4-8246-4d86-d982-b5f66bbec917"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict sentence : finding an trump the trump of the of of of of of \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "of8RWISJSjdb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}